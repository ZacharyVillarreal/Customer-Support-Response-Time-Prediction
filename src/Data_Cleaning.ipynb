{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:30:21.610940Z",
     "start_time": "2020-05-12T18:30:21.553420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from Helper import *\n",
    "import math\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy \n",
    "from langid.langid import LanguageIdentifier, model\n",
    "\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import emoji\n",
    "import spacy\n",
    "import string\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataframe_clean('../../../../Downloads/customer-support-on-twitter/twcs/twcs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['lemmatized_text'] = tweets.customer_tweet_text.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.lemmatized_text = tweets.lemmatized_text.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess customer_tweet_text\n",
    "tweets.customer_tweet_text = tweets.customer_tweet_text.apply(lambda x: preprocessing(x))\n",
    "#Preprocess company_response_text\n",
    "tweets.company_response_text = tweets.company_response_text.apply(lambda x: preprocessing(x))\n",
    "\n",
    "#Joining list of words into a string\n",
    "tweets.customer_tweet_text = tweets.customer_tweet_text.apply(lambda x: \" \".join(x))\n",
    "\n",
    "#Removing non-english text\n",
    "mask = set_english(tweets, 'customer_tweet_text')\n",
    "tweets['lang'] = mask\n",
    "tweets= tweets[tweets['lang'] == 'en']\n",
    "tweets.drop('lang', axis = 1, inplace = True)\n",
    "\n",
    "#Saving dataframe\n",
    "tweets.to_csv('../data/customer_support_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda7d173c5ac3d647bb86950a56c57e9e53"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
